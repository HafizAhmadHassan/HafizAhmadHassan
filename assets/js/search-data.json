{
  
    
        "post0": {
            "title": "2. Neural Network From Scratch",
            "content": "Neural Network From Scratch Using Pytorch and FAST.AI Capabilities . This tutorial is created from Lecture 4 from FAST ai Course Deep Learning from coders Course I will go through step by step how to build Classifier using pytorch from scratch. . Import Packages . Un comment &quot;!pip install -Uqq fastbook&quot; install if running colab . Download Dataset . Using Fastai function with untardata we are downloading images of 3s and 7s from MNIST dataset it is downloaded as zip file where function unzip it . path = untar_data(URLs.MNIST_SAMPLE) . path . Path(&#39;/home/hassan/.fastai/data/mnist_sample&#39;) . Point to Current Directory to Path . Path.BASE_PATH = path . Lets see whats inside Path . ls is special funtion which returns name of folder inside the path and number of folders as #x where x is count . path.ls() . (#3) [Path(&#39;train&#39;),Path(&#39;valid&#39;),Path(&#39;labels.csv&#39;)] . (path/&#39;train&#39;).ls() . (#2) [Path(&#39;train/7&#39;),Path(&#39;train/3&#39;)] . sevens = (path/&#39;train&#39;/&#39;7&#39;).ls().sorted() threes = (path/&#39;train&#39;/&#39;3&#39;).ls().sorted() . sevens . (#6265) [Path(&#39;train/7/10002.png&#39;),Path(&#39;train/7/1001.png&#39;),Path(&#39;train/7/10014.png&#39;),Path(&#39;train/7/10019.png&#39;),Path(&#39;train/7/10039.png&#39;),Path(&#39;train/7/10046.png&#39;),Path(&#39;train/7/10050.png&#39;),Path(&#39;train/7/10063.png&#39;),Path(&#39;train/7/10077.png&#39;),Path(&#39;train/7/10086.png&#39;)...] . Differnet methods to See Pic . Picture is actually represented as matrix of 3 dimension i.e (x,y,z) where z=1 or null in case of grey scale Usually it is 2 dimention and z=3 in case of RBG (colored image) and x and y are real numbers . Lets do following . Read/Get a path of image | Pass it to Image opener by python library | im3_path = threes[1] im3 = Image.open(im3_path) im3 . See image as Array . array(im3)[4:10,4:10] . array([[ 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 29], [ 0, 0, 0, 48, 166, 224], [ 0, 93, 244, 249, 253, 187], [ 0, 107, 253, 253, 230, 48], [ 0, 3, 20, 20, 15, 0]], dtype=uint8) . Tensors are Array in Pytorch . The 4:10 indicates we requested the rows from index 4 (included) to 10 (not included) . tensor(im3)[4:10,4:10] . tensor([[ 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 29], [ 0, 0, 0, 48, 166, 224], [ 0, 93, 244, 249, 253, 187], [ 0, 107, 253, 253, 230, 48], [ 0, 3, 20, 20, 15, 0]], dtype=torch.uint8) . Lets see image in a fancy way . Tensor casted as python data frame and style property allow us to visualise it in a good way | pd.DataFrame(tensor(im3)[4:15,3:22]).style.set_properties(**{&#39;font-size&#39;:&#39;6pt&#39;}).background_gradient(&#39;Greys&#39;) . &nbsp; 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 0 | 0 | 0 | 0 | 0 | 29 | 150 | 195 | 254 | 255 | 254 | 176 | 193 | 150 | 96 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 48 | 166 | 224 | 253 | 253 | 234 | 196 | 253 | 253 | 253 | 253 | 233 | 0 | 0 | 0 | . 3 0 | 0 | 93 | 244 | 249 | 253 | 187 | 46 | 10 | 8 | 4 | 10 | 194 | 253 | 253 | 233 | 0 | 0 | 0 | . 4 0 | 0 | 107 | 253 | 253 | 230 | 48 | 0 | 0 | 0 | 0 | 0 | 192 | 253 | 253 | 156 | 0 | 0 | 0 | . 5 0 | 0 | 3 | 20 | 20 | 15 | 0 | 0 | 0 | 0 | 0 | 43 | 224 | 253 | 245 | 74 | 0 | 0 | 0 | . 6 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 249 | 253 | 245 | 126 | 0 | 0 | 0 | 0 | . 7 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 14 | 101 | 223 | 253 | 248 | 124 | 0 | 0 | 0 | 0 | 0 | . 8 0 | 0 | 0 | 0 | 0 | 0 | 11 | 166 | 239 | 253 | 253 | 253 | 187 | 30 | 0 | 0 | 0 | 0 | 0 | . 9 0 | 0 | 0 | 0 | 0 | 0 | 16 | 248 | 250 | 253 | 253 | 253 | 253 | 232 | 213 | 111 | 2 | 0 | 0 | . 10 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 43 | 98 | 98 | 208 | 253 | 253 | 253 | 253 | 187 | 22 | 0 | . Images as Tensor List . Iterate through all paths of images 3/7 | open it as an images | cast it to tensor | Store it as list | sevens_list = [tensor(Image.open(o)) for o in sevens] threes_list = [tensor(Image.open(o)) for o in threes] . type(sevens_list), type(sevens_list[0]) . (list, torch.Tensor) . show_image(sevens_list[0]) . &lt;AxesSubplot:&gt; . Lets Store it as Tensor Stack . sevens_stack = torch.stack(sevens_list).float()/255 threes_stack = torch.stack(threes_list).float()/255 . type(sevens_stack) . torch.Tensor . Compare the types above . type(sevens_list), type(sevens_list[0]) . (list, torch.Tensor) . Put All things Together for Validation . valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;3&#39;).ls()]) valid_3_tens = valid_3_tens.float()/255 valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;7&#39;).ls()]) valid_7_tens = valid_7_tens.float()/255 valid_3_tens.shape,valid_7_tens.shape . (torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28])) . Prepare Training Data . type([sevens_stack, threes_stack]) ,len([sevens_stack, threes_stack]) . (list, 2) . Lets Reshape images to Dimenstion 1 . train_x = torch.cat([sevens_stack, threes_stack]).view(-1,28*28) . type(train_x),type(train_x[0]), train_x.shape . (torch.Tensor, torch.Tensor, torch.Size([12396, 784])) . Prepare Labels . I want to have all sevens as 0 | all threes as 1 | with Unsequeeze I can have Row vector See what is row vector in google | train_y = tensor([0]*len(sevens_stack) + [1]*len(threes_stack)).unsqueeze(1) . Pytorch Data Set . A Dataset in PyTorch is required to return a tuple of (x,y) when indexed. Python provides a zip function which, when combined with list, provides a simple way to get this functionality: . dset = list(zip(train_x,train_y)) . x,y = dset[0] . x.shape,y.shape . (torch.Size([784]), torch.Size([1])) . Prepare Testing Data . Same as training data preperation . valid_x = torch.cat([valid_7_tens ,valid_3_tens]).view(-1,28*28) valid_y = tensor([0]*len(valid_7_tens )+ [1]* len(valid_3_tens)).unsqueeze(1) valid_dset=list(zip(valid_x,valid_y)) . valid_x.shape,valid_y.shape . (torch.Size([2038, 784]), torch.Size([2038, 1])) . Data Loaders : Pytorch API . Lets Explore what is it . Lets see capability of batching -mini batch | dl = DataLoader(range(15), batch_size=5,shuffle=True) . list(dl) . [tensor([ 3, 12, 8, 10, 2]), tensor([ 9, 4, 7, 14, 5]), tensor([ 1, 13, 0, 6, 11])] . ds=DataLoader(L(enumerate(string.ascii_lowercase)), batch_size=5, shuffle=True) . list(ds) . [(tensor([17, 18, 10, 22, 8]), (&#39;r&#39;, &#39;s&#39;, &#39;k&#39;, &#39;w&#39;, &#39;i&#39;)), (tensor([14, 20, 15, 9, 13]), (&#39;o&#39;, &#39;u&#39;, &#39;p&#39;, &#39;j&#39;, &#39;n&#39;)), (tensor([21, 12, 7, 25, 6]), (&#39;v&#39;, &#39;m&#39;, &#39;h&#39;, &#39;z&#39;, &#39;g&#39;)), (tensor([ 5, 11, 23, 1, 3]), (&#39;f&#39;, &#39;l&#39;, &#39;x&#39;, &#39;b&#39;, &#39;d&#39;)), (tensor([ 0, 24, 19, 16, 2]), (&#39;a&#39;, &#39;y&#39;, &#39;t&#39;, &#39;q&#39;, &#39;c&#39;)), (tensor([4]), (&#39;e&#39;,))] . DataLoaders . A DataLoader can be created from a Dataset . dl = DataLoader(dset, batch_size=256,shuffle=True) xb, yb = first(dl) . xb.shape, yb.shape . (torch.Size([256, 784]), torch.Size([256, 1])) . type(valid_dset),len(valid_dset[0]) . (list, 2) . valid_dl = DataLoader(valid_dset, batch_size=256,shuffle=True) v_xb, v_yb = first(valid_dl) . Initialise Parameters . Lets create a function pass parameters to which we require gradient | weights and biases are are to be initialise | def init_params(size,std=1.0): return (torch.randn(size)*std).requires_grad_() . weights = init_params((28*28,1)) . bias = init_params(1) . Forward Pass . matrix multiplication plus bias . def linear1(x): return x@weights +bias . First Batch . Lets look at this First function take a first minibatch created by data loaders . xb, yb = first(dl) . preds = linear1(train_x) . preds=linear1(xb) . yb.shape,train_y.shape . (torch.Size([256, 1]), torch.Size([12396, 1])) . train_y . tensor([[0], [0], [0], ..., [1], [1], [1]]) . yb . tensor([[0], [0], [1], [1], [0], [1], [0], [1], [0], [0], [0], [1], [0], [1], [1], [1], [0], [1], [0], [1], [0], [1], [0], [0], [1], [0], [0], [0], [1], [0], [1], [1], [0], [1], [0], [1], [1], [0], [1], [0], [0], [0], [0], [1], [0], [1], [0], [0], [0], [0], [1], [1], [1], [1], [0], [0], [1], [0], [0], [0], [1], [1], [0], [1], [1], [0], [0], [0], [1], [0], [0], [0], [0], [0], [1], [1], [0], [0], [1], [1], [0], [1], [0], [0], [0], [0], [0], [1], [1], [0], [1], [1], [0], [0], [0], [0], [1], [0], [0], [1], [0], [1], [0], [1], [1], [0], [1], [1], [1], [1], [0], [1], [1], [0], [1], [0], [1], [0], [0], [1], [1], [0], [1], [0], [1], [1], [1], [0], [1], [0], [1], [0], [0], [1], [1], [0], [1], [1], [1], [0], [1], [0], [0], [0], [1], [0], [0], [1], [0], [1], [1], [1], [1], [0], [1], [1], [0], [1], [1], [0], [1], [0], [1], [0], [1], [1], [0], [0], [1], [1], [0], [0], [1], [1], [0], [1], [0], [0], [0], [1], [1], [0], [0], [0], [1], [0], [0], [0], [0], [1], [1], [0], [1], [1], [0], [1], [1], [1], [1], [0], [1], [1], [1], [1], [1], [1], [0], [0], [1], [0], [0], [0], [1], [0], [0], [0], [1], [0], [1], [1], [0], [1], [0], [0], [0], [0], [0], [1], [0], [0], [0], [0], [0], [0], [1], [1], [0], [1], [1], [0], [0], [1], [1], [0], [1], [1], [0], [1], [0], [0], [1], [0], [0], [1], [0], [0]]) . . Step Function as an Activation . Here we have step function as activation Predictions which are greater than 0.5 are considered one class another is second . corrects =(preds&gt;0.5).float() == yb . . corrects.float().mean().item() . 0.40625 . Loss Calculations . since we want to restrict our prediction to range [0-1] as we have labels 0 for seven class and 1 for three class . def mnist_loss(predictions,targets): predictions = predictions.sigmoid() return torch.where(targets==1, (1-predictions), predictions).mean() . loss = mnist_loss(corrects,yb) . Claculate Gradient . take predictions | calculate loss | derivative of loss w.r.t parameters : weights and bias | def calc_grad(x,y,model): preds = model(x) loss = mnist_loss(preds,y) loss.backward() . calc_grad(xb,yb,linear1) . weights.grad.shape,weights.grad.mean(),bias.grad . (torch.Size([784, 1]), tensor(-0.0013), tensor([-0.0049])) . Why Gradzero? . Our only remaining step is to update the weights and biases based on the gradient and learning rate. When we do so, we have to tell PyTorch not to take the gradient of this step too—otherwise things will get very confusing when we try to compute the derivative at the next batch! If we assign to the data attribute of a tensor then PyTorch will not take the gradient of that step. Here&#39;s our basic training loop for an epoch . weights.grad.zero_(),bias.grad.zero_(); . def train_epoch(model,lr,params): for x,y in dl: calc_grad(x,y,model) for p in params: p.data -= p.grad*lr p.grad.zero_() . batch accuracy used to evaluate model . def batch_accuracy(xb, yb): preds = xb.sigmoid() correct = (preds&gt;0.5) == yb return correct.float().mean() . batch_accuracy(linear1(xb), yb) . tensor(0.4102) . def validate_epoch(model): accs = [batch_accuracy(model(v_xb), v_yb) for v_xb,v_yb in valid_dl] return round(torch.stack(accs).mean().item(), 4) . validate_epoch(linear1) . 0.4655 . Lets Start out Training . learning rate here 10 to power -1 | validate used to evaluate model on validation data | lr = 1e-1 params = weights,bias train_epoch(linear1, lr, params) validate_epoch(linear1) . 0.5633 . for i in range(400): train_epoch(linear1, lr, params) print(validate_epoch(linear1), end=&#39; &#39;) . 0.7051 0.7993 0.8414 0.8735 0.8907 0.9004 0.9122 0.9205 0.9275 0.9319 0.9362 0.9367 0.9373 0.9396 0.9417 0.9431 0.9445 0.9445 0.9465 0.9466 0.9494 0.9499 0.9509 0.9519 0.9545 0.9559 0.9559 0.9559 0.9564 0.9572 0.9587 0.9588 0.9597 0.9607 0.9608 0.9627 0.9627 0.9632 0.9637 0.9642 0.9642 0.9641 0.9646 0.9647 0.9651 0.9657 0.9656 0.9661 0.9657 0.9661 0.9667 0.9667 0.9667 0.9666 0.9676 0.9675 0.9676 0.9681 0.9686 0.9686 0.9686 0.9691 0.9692 0.9691 0.969 0.9695 0.9695 0.97 0.9701 0.9701 0.97 0.9701 0.9701 0.9701 0.971 0.9711 0.9716 0.9715 0.9721 0.972 0.972 0.9726 0.9726 0.9725 0.9726 0.9726 0.9725 0.9725 0.9725 0.9726 0.9726 0.9723 0.9725 0.9736 0.9735 0.974 0.974 0.974 0.9745 0.9745 0.9745 0.9745 0.9749 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.9749 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.9754 0.9754 0.9755 0.9754 0.9755 0.9754 0.9755 0.9755 0.976 0.9765 0.9765 0.9765 0.9765 0.9764 0.9765 0.9764 0.9764 0.9764 0.9765 0.9765 0.9765 0.9764 0.9765 0.9765 0.9764 0.9765 0.9765 0.9764 0.9764 0.9764 0.9765 0.9763 0.9764 0.9764 0.9764 0.9764 0.9765 0.9765 0.9765 0.9765 0.9765 0.9764 0.9764 0.9765 0.9765 0.9764 0.9765 0.9765 0.9765 0.9765 0.9765 0.9764 0.9765 0.9765 0.9769 0.977 0.977 0.9769 0.977 0.977 0.977 0.977 0.9769 0.977 0.977 0.9769 0.977 0.9769 0.977 0.9775 0.9774 0.9775 0.9775 0.9774 0.9774 0.9773 0.9774 0.9774 0.9775 0.9774 0.9775 0.9773 0.9774 0.9774 0.9774 0.9775 0.9775 0.9774 0.9774 0.9774 0.9774 0.9774 0.9774 0.9774 0.9775 0.9775 0.9774 0.9774 0.9775 0.9779 0.9779 0.9778 0.9779 0.9779 0.9778 0.9779 0.9779 0.9779 0.9779 0.9784 0.9784 0.9785 0.9784 0.9784 0.9784 0.9784 0.9785 0.9783 0.9783 0.9784 0.9789 0.9789 0.9789 0.9789 0.9789 0.9789 0.979 0.9788 0.979 0.9789 0.9789 0.9789 0.9789 0.9789 0.9789 0.979 0.9789 0.9789 0.9789 0.9789 0.9789 0.9788 0.979 0.9789 0.9789 0.9789 0.9788 0.9788 0.979 0.9789 0.979 0.9789 0.9789 0.9789 0.9788 0.9789 0.9789 0.9794 0.9794 0.9793 0.9795 0.9794 0.9794 0.9793 0.9794 0.9794 0.9794 0.9795 0.9795 0.9794 0.9794 0.9794 0.9794 0.9794 0.9794 0.9794 0.9794 0.9799 0.9798 0.9799 0.9798 0.98 0.9799 0.9799 0.9799 0.9798 0.9799 0.9798 0.9799 0.9799 0.9799 0.9798 0.9799 0.9799 0.9799 0.9799 0.9799 0.9798 0.9799 0.9799 0.9799 0.9799 0.9799 0.9799 0.9799 0.9799 0.9799 0.9799 0.9799 0.9798 0.9798 0.9799 0.9798 0.9799 0.9799 0.9799 0.9799 0.9798 0.9799 0.9799 0.9799 0.9799 0.9798 0.9799 0.9799 0.9798 0.9799 0.9799 0.9799 0.9799 0.9799 0.9798 0.9799 0.9799 0.9799 0.9798 0.9799 0.9798 0.9799 0.9799 0.9799 0.9799 0.9798 0.9799 0.9799 0.9798 0.9799 0.9798 0.9799 0.9799 0.9799 0.9798 0.9798 0.9799 0.9799 0.9799 0.9799 0.9803 0.9804 0.9803 0.9804 0.9803 0.9804 0.9804 0.9804 0.9804 0.9804 0.9804 0.9804 0.9804 0.9804 0.9803 0.9803 0.9803 0.9804 0.9804 0.9804 0.9804 . . Using Python Class . Using same &#39;nn.linear&#39; module inherits object pytorch class &#39;nn.Linear&#39; . nn.Linear does the same thing as our init_params and linear together. It contains both the weights and biases in a single class. Here&#39;s how we replicate our model from the previous section: . linear_model =nn.Linear(28*28,1) . w,b = linear_model.parameters() w.shape, b.shape . (torch.Size([1, 784]), torch.Size([1])) . class BasicOpt: #class contains two attributes params=weights,bias and learning rate # get all the parameters def __init__(self, params,lr): self.params, self.lr = list(params),lr # gradient def step(self, *args, **kwargs): for p in self.params: p.data -= p.grad.data * self.lr # zero grad def zero_grad(self, *args , **kwargs): for p in self.params: p.grad = None . opt = BasicOpt(linear_model.parameters(), lr=1e-1) . def train_epoch(model): for x,y in dl: calc_grad(x,y,model) opt.step() opt.zero_grad() . validate_epoch(linear_model) . 0.6556 . def train_model(model,epochs): for i in range(epochs): train_epoch(model) print(validate_epoch(linear_model),end=&quot; &quot; ) . train_model(model=linear_model, epochs = 10) . 0.9657 0.9672 0.9676 0.9686 0.9695 0.9706 0.9706 0.9711 0.9716 0.972 . linear_model = nn.Linear(28*28,1) opt = SGD(linear_model.parameters(), lr =1e-1) train_model(linear_model,20) . 0.9651 0.9657 0.9687 0.9701 0.9695 0.9705 0.9706 0.971 0.9721 0.973 0.9729 0.973 0.973 0.974 0.9745 0.975 0.9755 0.9754 0.9754 0.9754 . dls = DataLoaders(dl, valid_dl) . To create a Learner without using an application (such as cnn_learner) we need to pass in all the elements that we&#39;ve created in this chapter: the DataLoaders, the model, the optimization function (which will be passed the parameters), the loss function, and optionally any metrics to print: . learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy) . Now we can call fit: . learn.fit(10, lr=lr) . epoch train_loss valid_loss batch_accuracy time . 0 | 0.154314 | 0.093394 | 0.967125 | 00:00 | . 1 | 0.097860 | 0.069815 | 0.967615 | 00:00 | . 2 | 0.074141 | 0.059789 | 0.969578 | 00:00 | . 3 | 0.062189 | 0.054248 | 0.970069 | 00:00 | . 4 | 0.054846 | 0.050518 | 0.970069 | 00:00 | . 5 | 0.049594 | 0.047826 | 0.970559 | 00:00 | . 6 | 0.045887 | 0.045634 | 0.970559 | 00:00 | . 7 | 0.043330 | 0.044017 | 0.970559 | 00:00 | . 8 | 0.041645 | 0.042539 | 0.972031 | 00:00 | . 9 | 0.039802 | 0.041379 | 0.972031 | 00:00 | .",
            "url": "https://hafizahmadhassan.github.io/HafizAhmadHassan/jupyter/2021/09/03/SDG-4.html",
            "relUrl": "/jupyter/2021/09/03/SDG-4.html",
            "date": " • Sep 3, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Neural Network From Scratch",
            "content": "Download Dataset . . path = untar_data(URLs.MNIST_SAMPLE) . path . Path(&#39;/home/hassan/.fastai/data/mnist_sample&#39;) . Point to Current Directory This is on Ram . Path.BASE_PATH = path . Return Number of Counts . path.ls() . (#3) [Path(&#39;train&#39;),Path(&#39;valid&#39;),Path(&#39;labels.csv&#39;)] . (path/&#39;train&#39;).ls() . (#2) [Path(&#39;train/7&#39;),Path(&#39;train/3&#39;)] . sevens = (path/&#39;train&#39;/&#39;7&#39;).ls().sorted() threes = (path/&#39;train&#39;/&#39;3&#39;).ls().sorted() . sevens . (#6265) [Path(&#39;train/7/10002.png&#39;),Path(&#39;train/7/1001.png&#39;),Path(&#39;train/7/10014.png&#39;),Path(&#39;train/7/10019.png&#39;),Path(&#39;train/7/10039.png&#39;),Path(&#39;train/7/10046.png&#39;),Path(&#39;train/7/10050.png&#39;),Path(&#39;train/7/10063.png&#39;),Path(&#39;train/7/10077.png&#39;),Path(&#39;train/7/10086.png&#39;)...] . Differnet methods to see pic . im3_path = threes[1] im3 = Image.open(im3_path) im3 . array(im3)[4:10,4:10] . array([[ 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 29], [ 0, 0, 0, 48, 166, 224], [ 0, 93, 244, 249, 253, 187], [ 0, 107, 253, 253, 230, 48], [ 0, 3, 20, 20, 15, 0]], dtype=uint8) . tensor(im3)[4:10,4:10] . tensor([[ 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 29], [ 0, 0, 0, 48, 166, 224], [ 0, 93, 244, 249, 253, 187], [ 0, 107, 253, 253, 230, 48], [ 0, 3, 20, 20, 15, 0]], dtype=torch.uint8) . pd.DataFrame(tensor(im3)[4:15,3:22]).style.set_properties(**{&#39;font-size&#39;:&#39;6pt&#39;}).background_gradient(&#39;Greys&#39;) . &nbsp; 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 0 | 0 | 0 | 0 | 0 | 29 | 150 | 195 | 254 | 255 | 254 | 176 | 193 | 150 | 96 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 48 | 166 | 224 | 253 | 253 | 234 | 196 | 253 | 253 | 253 | 253 | 233 | 0 | 0 | 0 | . 3 0 | 0 | 93 | 244 | 249 | 253 | 187 | 46 | 10 | 8 | 4 | 10 | 194 | 253 | 253 | 233 | 0 | 0 | 0 | . 4 0 | 0 | 107 | 253 | 253 | 230 | 48 | 0 | 0 | 0 | 0 | 0 | 192 | 253 | 253 | 156 | 0 | 0 | 0 | . 5 0 | 0 | 3 | 20 | 20 | 15 | 0 | 0 | 0 | 0 | 0 | 43 | 224 | 253 | 245 | 74 | 0 | 0 | 0 | . 6 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 249 | 253 | 245 | 126 | 0 | 0 | 0 | 0 | . 7 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 14 | 101 | 223 | 253 | 248 | 124 | 0 | 0 | 0 | 0 | 0 | . 8 0 | 0 | 0 | 0 | 0 | 0 | 11 | 166 | 239 | 253 | 253 | 253 | 187 | 30 | 0 | 0 | 0 | 0 | 0 | . 9 0 | 0 | 0 | 0 | 0 | 0 | 16 | 248 | 250 | 253 | 253 | 253 | 253 | 232 | 213 | 111 | 2 | 0 | 0 | . 10 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 43 | 98 | 98 | 208 | 253 | 253 | 253 | 253 | 187 | 22 | 0 | . sevens_list = [tensor(Image.open(o)) for o in sevens] threes_list = [tensor(Image.open(o)) for o in threes] . type(sevens_list), type(sevens_list[0]) . (list, torch.Tensor) . show_image(sevens_list[0]) . &lt;AxesSubplot:&gt; . Lets Stack as Tensor . sevens_stack = torch.stack(sevens_list).float()/255 threes_stack = torch.stack(threes_list).float()/255 . type(sevens_stack) . torch.Tensor . Compare the types above . type(sevens_list), type(sevens_list[0]) . (list, torch.Tensor) . Put All things Together for Validation . valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;3&#39;).ls()]) valid_3_tens = valid_3_tens.float()/255 valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;7&#39;).ls()]) valid_7_tens = valid_7_tens.float()/255 valid_3_tens.shape,valid_7_tens.shape . (torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28])) . Prepare Training Data . type([sevens_stack, threes_stack]) ,len([sevens_stack, threes_stack]) . (list, 2) . train_x = torch.cat([sevens_stack, threes_stack]).view(-1,28*28) . type(train_x),type(train_x[0]), train_x.shape . (torch.Tensor, torch.Tensor, torch.Size([12396, 784])) . train_y = tensor([0]*len(sevens_stack) + [1]*len(threes_stack)).unsqueeze(1) . . dset = list(zip(train_x,train_y)) . x,y = dset[0] . x.shape,y.shape . (torch.Size([784]), torch.Size([1])) . Prepare Testing Data . valid_x = torch.cat([valid_7_tens ,valid_3_tens]).view(-1,28*28) valid_y = tensor([0]*len(valid_7_tens )+ [1]* len(valid_3_tens)).unsqueeze(1) valid_dset=list(zip(valid_x,valid_y)) . valid_x.shape,valid_y.shape . (torch.Size([2038, 784]), torch.Size([2038, 1])) . Data Loaders : Pytorch API . dl = DataLoader(range(15), batch_size=5,shuffle=True) . list(dl) . [tensor([ 3, 12, 8, 10, 2]), tensor([ 9, 4, 7, 14, 5]), tensor([ 1, 13, 0, 6, 11])] . ds=DataLoader(L(enumerate(string.ascii_lowercase)), batch_size=5, shuffle=True) . list(ds) . [(tensor([17, 18, 10, 22, 8]), (&#39;r&#39;, &#39;s&#39;, &#39;k&#39;, &#39;w&#39;, &#39;i&#39;)), (tensor([14, 20, 15, 9, 13]), (&#39;o&#39;, &#39;u&#39;, &#39;p&#39;, &#39;j&#39;, &#39;n&#39;)), (tensor([21, 12, 7, 25, 6]), (&#39;v&#39;, &#39;m&#39;, &#39;h&#39;, &#39;z&#39;, &#39;g&#39;)), (tensor([ 5, 11, 23, 1, 3]), (&#39;f&#39;, &#39;l&#39;, &#39;x&#39;, &#39;b&#39;, &#39;d&#39;)), (tensor([ 0, 24, 19, 16, 2]), (&#39;a&#39;, &#39;y&#39;, &#39;t&#39;, &#39;q&#39;, &#39;c&#39;)), (tensor([4]), (&#39;e&#39;,))] . dl = DataLoader(dset, batch_size=256,shuffle=True) xb, yb = first(dl) . xb.shape, yb.shape . (torch.Size([256, 784]), torch.Size([256, 1])) . type(valid_dset),len(valid_dset[0]) . (list, 2) . valid_dl = DataLoader(valid_dset, batch_size=256,shuffle=True) v_xb, v_yb = first(valid_dl) . Initialise Parameters . def init_params(size,std=1.0): return (torch.randn(size)*std).requires_grad_() . weights = init_params((28*28,1)) . bias = init_params(1) . Forward Pass . def linear1(x): return x@weights +bias . Lets see the first Batch . xb, yb = first(dl) . preds = linear1(train_x) . preds=linear1(xb) . yb.shape,train_y.shape . (torch.Size([256, 1]), torch.Size([12396, 1])) . train_y . tensor([[0], [0], [0], ..., [1], [1], [1]]) . yb . tensor([[0], [0], [1], [1], [0], [1], [0], [1], [0], [0], [0], [1], [0], [1], [1], [1], [0], [1], [0], [1], [0], [1], [0], [0], [1], [0], [0], [0], [1], [0], [1], [1], [0], [1], [0], [1], [1], [0], [1], [0], [0], [0], [0], [1], [0], [1], [0], [0], [0], [0], [1], [1], [1], [1], [0], [0], [1], [0], [0], [0], [1], [1], [0], [1], [1], [0], [0], [0], [1], [0], [0], [0], [0], [0], [1], [1], [0], [0], [1], [1], [0], [1], [0], [0], [0], [0], [0], [1], [1], [0], [1], [1], [0], [0], [0], [0], [1], [0], [0], [1], [0], [1], [0], [1], [1], [0], [1], [1], [1], [1], [0], [1], [1], [0], [1], [0], [1], [0], [0], [1], [1], [0], [1], [0], [1], [1], [1], [0], [1], [0], [1], [0], [0], [1], [1], [0], [1], [1], [1], [0], [1], [0], [0], [0], [1], [0], [0], [1], [0], [1], [1], [1], [1], [0], [1], [1], [0], [1], [1], [0], [1], [0], [1], [0], [1], [1], [0], [0], [1], [1], [0], [0], [1], [1], [0], [1], [0], [0], [0], [1], [1], [0], [0], [0], [1], [0], [0], [0], [0], [1], [1], [0], [1], [1], [0], [1], [1], [1], [1], [0], [1], [1], [1], [1], [1], [1], [0], [0], [1], [0], [0], [0], [1], [0], [0], [0], [1], [0], [1], [1], [0], [1], [0], [0], [0], [0], [0], [1], [0], [0], [0], [0], [0], [0], [1], [1], [0], [1], [1], [0], [0], [1], [1], [0], [1], [1], [0], [1], [0], [0], [1], [0], [0], [1], [0], [0]]) . Step Function as an Activation . corrects =(preds&gt;0.5).float() == yb . . corrects.float().mean().item() . 0.3203125 . LOSS CALCULATION . def mnist_loss(predictions,targets): predictions = predictions.sigmoid() return torch.where(targets==1, (1-predictions), predictions).mean() . loss = mnist_loss(corrects,yb) . GRADIENT . def calc_grad(x,y,model): preds = model(x) loss = mnist_loss(preds,y) loss.backward() . calc_grad(xb,yb,linear1) . weights.grad.shape,weights.grad.mean(),bias.grad . (torch.Size([784, 1]), tensor(-0.0029), tensor([-0.0199])) . weights.grad.zero_(),bias.grad.zero_(); . def train_epoch(model,lr,params): for x,y in dl: calc_grad(x,y,model) for p in params: p.data -= p.grad*lr p.grad.zero_() . def batch_accuracy(xb, yb): preds = xb.sigmoid() correct = (preds&gt;0.5) == yb return correct.float().mean() . batch_accuracy(linear1(xb), yb) . tensor(0.3242) . def validate_epoch(model): accs = [batch_accuracy(model(v_xb), v_yb) for v_xb,v_yb in valid_dl] return round(torch.stack(accs).mean().item(), 4) . validate_epoch(linear1) . 0.3109 . lr = 1e-1 params = weights,bias train_epoch(linear1, lr, params) validate_epoch(linear1) . 0.4096 . for i in range(400): train_epoch(linear1, lr, params) print(validate_epoch(linear1), end=&#39; &#39;) . 0.4563 0.4724 0.4789 0.4832 0.4868 0.4882 0.4892 0.4899 0.4911 0.4921 0.4924 0.4919 0.4926 0.4933 0.4941 0.494 0.4945 0.4949 0.4947 0.4953 0.4951 0.4949 0.4951 0.4951 0.4952 0.4955 0.4951 0.4951 0.4951 0.4952 0.4951 0.4948 0.4948 0.4951 0.4955 0.4957 0.4957 0.4955 0.4958 0.4956 0.4957 0.4955 0.4959 0.4958 0.4956 0.496 0.4956 0.4955 0.4956 0.4955 0.4957 0.4953 0.4957 0.4957 0.4959 0.4956 0.4955 0.4958 0.4955 0.4955 0.4955 0.4955 0.4955 0.4954 0.4956 0.4954 0.4956 0.4954 0.4954 0.4957 0.4957 0.4955 0.4954 0.4954 0.4956 0.4955 0.4957 0.4957 0.4957 0.4955 0.4957 0.4956 0.4956 0.4957 0.4956 0.4956 0.4954 0.4957 0.4954 0.4956 0.4957 0.4954 0.4958 0.4957 0.4957 0.4956 0.4956 0.4956 0.4954 0.4956 0.4955 0.4955 0.4956 0.4953 0.4955 0.4957 0.4958 0.4957 0.4953 0.4955 0.4955 0.4957 0.4957 0.4955 0.4956 0.4956 0.4958 0.4957 0.4955 0.4956 0.4957 0.4956 0.4955 0.4955 0.4953 0.4953 0.4954 0.4955 0.4956 0.4956 0.4957 0.4956 0.4956 0.4953 0.4956 0.4957 0.4956 0.4958 0.4953 0.4956 0.4956 0.4956 0.4956 0.4955 0.4955 0.4956 0.4956 0.4956 0.4954 0.4954 0.4954 0.4955 0.4957 0.4958 0.4954 0.4951 0.4955 0.4955 0.4957 0.4953 0.4958 0.4957 0.4956 0.4956 0.4957 0.4957 0.496 0.4962 0.4962 0.4957 0.4961 0.4961 0.496 0.4961 0.4963 0.4961 0.4961 0.496 0.4961 0.4962 0.496 0.4961 0.4963 0.4962 0.4961 0.4961 0.4962 0.4959 0.4964 0.4963 0.4963 0.4958 0.4962 0.496 0.4961 0.4961 0.496 0.4958 0.496 0.496 0.4962 0.4962 0.4961 0.4959 0.4962 0.4959 0.4961 0.4961 0.496 0.4961 0.4964 0.4964 0.4962 0.4964 0.4961 0.4961 0.4958 0.496 0.4962 0.4962 0.4956 0.4962 0.4962 0.4964 0.4961 0.4961 0.4963 0.4959 0.4962 0.4963 0.4957 0.4959 0.4962 0.4962 0.496 0.4961 0.4961 0.496 0.496 0.4966 0.4969 0.4969 0.4969 0.4965 0.4978 0.4979 0.4985 0.4997 0.5023 0.5037 0.5099 0.523 0.5494 0.6028 0.736 0.8277 0.8562 0.8794 0.8885 0.901 0.9034 0.9131 0.9196 0.9243 0.9279 0.9289 0.9318 0.9353 0.9361 0.9371 0.9396 0.9402 0.9407 0.9421 0.9444 0.9455 0.946 0.9476 0.9499 0.9515 0.9525 0.9523 0.9535 0.9539 0.9544 0.9544 0.9544 0.9548 0.9563 0.9573 0.9579 0.9578 0.9583 0.9583 0.9584 0.9588 0.9588 0.9593 0.9592 0.9593 0.9592 0.9593 0.9592 0.9592 0.9598 0.9598 0.9603 0.9601 0.9598 0.9597 0.9603 0.9602 0.9602 0.9607 0.9607 0.9607 0.9607 0.9603 0.9602 0.9603 0.9602 0.9602 0.9606 0.9607 0.9607 0.9608 0.9608 0.9608 0.9608 0.9612 0.9617 0.9617 0.9617 0.9618 0.9616 0.9623 0.9623 0.9627 0.9627 0.9626 0.9632 0.9632 0.9633 0.9632 0.9632 0.9632 0.9632 0.9631 0.9632 0.9632 0.9633 0.9632 0.9632 0.9632 0.9632 0.9637 0.9637 0.9636 0.9632 0.9632 0.9631 0.9632 0.9632 0.9632 0.9641 0.9642 0.9647 0.9646 0.9647 0.9647 0.9662 0.966 0.9661 0.966 0.9666 0.9667 0.9671 0.9675 0.9677 0.9676 0.9681 0.9681 0.9681 0.9681 0.9686 0.9687 0.9686 0.9687 0.9686 0.9686 0.9686 0.9686 0.9686 0.969 0.9691 0.969 0.9691 0.9691 0.9692 0.9691 .",
            "url": "https://hafizahmadhassan.github.io/HafizAhmadHassan/2021/08/29/SDG-3.html",
            "relUrl": "/2021/08/29/SDG-3.html",
            "date": " • Aug 29, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://hafizahmadhassan.github.io/HafizAhmadHassan/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://hafizahmadhassan.github.io/HafizAhmadHassan/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://hafizahmadhassan.github.io/HafizAhmadHassan/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://hafizahmadhassan.github.io/HafizAhmadHassan/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}